cars2
cars2 = cbind(cars2, state)
cars2
data(cars)
print(head(cars,5))
set.seed(0)
state = sample(1:3, dim(cars[1]), replace = TRUE)
state = factor(state)
levels(state) = c('NY','CA','CT')
state
#print(head(cars2), 5)
ratio = cars['dist']/cars['speed']
cars2 = cbind(cars, state)
cars2 = cbind(cars, ratio)
print(head(cars2))
print(head(cars2))
data(cars)
print(head(cars,5))
set.seed(0)
state = sample(1:3, dim(cars[1]), replace = TRUE)
state = factor(state)
levels(state) = c('NY','CA','CT')
state
#print(head(cars2), 5)
ratio = cars['dist']/cars['speed']
cars2 = cbind(cars, state)
cars2 = cbind(cars2, ratio)
print(head(cars2))
data(cars)
print(head(cars,5))
set.seed(0)
state = sample(1:3, dim(cars[1]), replace = TRUE)
state = factor(state)
levels(state) = c('NY','CA','CT')
state
#print(head(cars2), 5)
ratio = cars['dist']/cars['speed']
cars2 = cbind(cars, state)
cars2 = cbind(cars2, ratio)
colnames(car2) = c('dist','speed','state','ratio')
data(cars)
print(head(cars,5))
set.seed(0)
state = sample(1:3, dim(cars[1]), replace = TRUE)
state = factor(state)
levels(state) = c('NY','CA','CT')
state
#print(head(cars2), 5)
ratio = cars['dist']/cars['speed']
cars2 = cbind(cars, state)
cars2 = cbind(cars2, ratio)
colnames(cars2) = c('dist','speed','state','ratio')
print(head(cars2))
data(cars)
print(head(cars,5))
set.seed(0)
state = sample(1:3, dim(cars[1]), replace = TRUE)
state = factor(state)
levels(state) = c('NY','CA','CT')
state
#print(head(cars2), 5)
ratio = cars['dist']/cars['speed']
cars2 = cbind(cars, state)
cars2 = cbind(cars2, ratio)
colnames(cars2) = c('dist','speed','state','ratio')
print(head(cars2))
print(mean(cars2['ratio']))
class(cars['ratio'])
class(cars2['ratio'])
mean(cars[2])
mean(float(cars[2]))
mean(as.float(cars[2]))
mean(as.numeric(cars[2]))
shiny::runApp('NYCDSA_proj/projects/Nyc_Oil')
runApp('NYCDSA_proj/projects/Nyc_Oil')
setwd("~/NYCDSA_proj/projects/Nyc_Oil")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?renderGvis
?htmlOutput
runApp()
combined_map2 = ggplot() +
geom_polygon(data = counties, aes(x=long, y=lat, group = group)) +
geom_point(data = filtered_oil2(), aes(x = Longitude, y = Latitude, color = Building.Type)) +
theme(axis.title.x = element_blank(),
axis.text.x=element_blank(),
axis.ticks = element_blank(),
axis.title.y = element_blank(),
axis.text.y=element_blank()
)
combined_map2
map2 = ggplot() + geom_polygon(data=map_part, aes(x = long, y = lat, group = group)) + theme(plot.subtitle = element_text(vjust = 1),
plot.caption = element_text(vjust = 1),
legend.position = "none")
map2 = ggplot() + geom_polygon(data=map_part, aes(x = long, y = lat, group = group)) + theme(plot.subtitle = element_text(vjust = 1),
plot.caption = element_text(vjust = 1),
legend.position = "none")
map2 = ggplot() + geom_polygon(data=map_part, aes(x = long, y = lat, group = group)) + theme(plot.subtitle = element_text(vjust = 1),
plot.caption = element_text(vjust = 1),
legend.position = "none")
library(ggplot2)
library(maps)
library(dplyr)
library(mapdata)
library(rgdal)
library(maptools)
#energy = read.csv('Energy_use.csv')
oil = read.csv('oil_boilers.csv')
#we'll look at data on oil_boilers in NYC
#let's start by inspecting data
print(dim(oil))
print(sum(is.na(oil$Latitude)))
print(colnames(oil))
#let's get an idea of of how many values are not on map
# about 40% of entrys have no lat/long.
# let's get a better idea of whats missing and what we can extrapolate
#first. Which boroughs is this data missing
# compare number of missing data to how much is there per borough
na_count = oil %>%
group_by(., Borough) %>%
summarise(., count_na = sum(is.na(Latitude)), counts = n()) %>%
mutate(., perc_missing = count_na/counts * 100)
#turns out the most missing data is from manhattan
#but there are so many data points there it might not matter
# let's explore what's left when we remove data w/o location
clean_oil = oil %>%
filter(., !is.na(Latitude)) %>%
rename(Retirement = Estimated.retirement.date.of.boiler..assuming.35.year.average.useful.life. )
#What questions do we want to answer with this data set?
#1. Where are these boilers located
#2. When where they installed
#3. How much fuel do they consume?
#3a. How much money is fuel is consumed?
#4. When are they due to being replaced?
## Main Thesis: NYC has dates set to phase out thousands of boilers in nyc between 2010 and 2040.
## Each burns hundreds of thousands of oil worth of btus a year.
## knowing when and where these units are being phased out would be useful in planning efforts to switch to gas units
## no 4 and no 6 are dirty burining oils. no 6 was to be phased out 2015
## all burners are mandated to be on no 2 or nat gas by 2030
## source https://www.nytimes.com/2014/04/07/nyregion/cost-among-hurdles-slowing-new-yorks-plan-to-phase-out-dirty-heating-oil.html
#messing with plotting spatial data
counties = readOGR("nycbb.shp", layer = "nycbb")
council = readOGR('nycc.shp', layer = 'nycc')
area = readShapePoly('nycc.shp')
nyc_base = ggplot() + geom_polygon(data = council, aes(x=long, y=lat, group = group))
# to split up code acros multiple rows, leave operator at the end of break
# did a search for borough boundary shp files
# https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm/data
# let's work on filtering data appropriately
year1 = 2039
year2 = 2040
filtered_oil = clean_oil %>%
filter(., Retirement >= year1 & Retirement <= year2) %>%
filter(., Natural.Gas.Utility..Con.Edison.or.National.Grid %in% c('National Grid'))
oil_district = clean_oil %>%
filter(.,)
combined_map = ggplot() +
geom_polygon(data = council, aes(x=long, y=lat, group = group)) +
geom_point(data = filtered_oil, aes(x = Longitude, y = Latitude, color = 'red'))
retire_count = filtered_oil %>%
group_by(., Borough) %>%
summarize(., count = n())
count_plot = ggplot(data=filtered_oil, aes(x = Borough))
borough = oil %>%
group_by(., Borough)%>%
summarize(., cnt = n())
leaflet_nyc_oil = leaflet() %>% addTiles() %>% addPolygons(data = council)
area.points = fortify(council)
b.points = fortify(counties)
b_filter = clean_oil %>%
filter(., Borough %in% 1) %>%
distinct(., Council.District)
map_part = b.points %>%
filter(., id %in% c(0:4))
map2 = ggplot() + geom_polygon(data=map_part, aes(x = long, y = lat, group = group)) + theme(plot.subtitle = element_text(vjust = 1),
plot.caption = element_text(vjust = 1),
legend.position = "none")
map2
runApp()
?tabItem
?fluidRow
?box
?htmlOutput
plotOutput()
?plotOutput
runApp()
runApp()
runApp()
?fluidRow
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
class(clean_oil$Borough)
library(ggplot2)
library(maps)
library(dplyr)
library(mapdata)
library(rgdal)
library(maptools)
#energy = read.csv('Energy_use.csv')
oil = read.csv('oil_boilers.csv')
#we'll look at data on oil_boilers in NYC
#let's start by inspecting data
print(dim(oil))
print(sum(is.na(oil$Latitude)))
print(colnames(oil))
#let's get an idea of of how many values are not on map
# about 40% of entrys have no lat/long.
# let's get a better idea of whats missing and what we can extrapolate
#first. Which boroughs is this data missing
# compare number of missing data to how much is there per borough
na_count = oil %>%
group_by(., Borough) %>%
summarise(., count_na = sum(is.na(Latitude)), counts = n()) %>%
mutate(., perc_missing = count_na/counts * 100)
#turns out the most missing data is from manhattan
#but there are so many data points there it might not matter
# let's explore what's left when we remove data w/o location
clean_oil = oil %>%
filter(., !is.na(Latitude)) %>%
rename(Retirement = Estimated.retirement.date.of.boiler..assuming.35.year.average.useful.life. )
#What questions do we want to answer with this data set?
#1. Where are these boilers located
#2. When where they installed
#3. How much fuel do they consume?
#3a. How much money is fuel is consumed?
#4. When are they due to being replaced?
## Main Thesis: NYC has dates set to phase out thousands of boilers in nyc between 2010 and 2040.
## Each burns hundreds of thousands of oil worth of btus a year.
## knowing when and where these units are being phased out would be useful in planning efforts to switch to gas units
## no 4 and no 6 are dirty burining oils. no 6 was to be phased out 2015
## all burners are mandated to be on no 2 or nat gas by 2030
## source https://www.nytimes.com/2014/04/07/nyregion/cost-among-hurdles-slowing-new-yorks-plan-to-phase-out-dirty-heating-oil.html
#messing with plotting spatial data
counties = readOGR("nycbb.shp", layer = "nycbb")
council = readOGR('nycc.shp', layer = 'nycc')
area = readShapePoly('nycc.shp')
nyc_base = ggplot() + geom_polygon(data = council, aes(x=long, y=lat, group = group))
# to split up code acros multiple rows, leave operator at the end of break
# did a search for borough boundary shp files
# https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm/data
# let's work on filtering data appropriately
year1 = 2039
year2 = 2040
filtered_oil = clean_oil %>%
filter(., Retirement >= year1 & Retirement <= year2) %>%
filter(., Natural.Gas.Utility..Con.Edison.or.National.Grid %in% c('National Grid'))
oil_district = clean_oil %>%
filter(.,)
combined_map = ggplot() +
geom_polygon(data = council, aes(x=long, y=lat, group = group)) +
geom_point(data = filtered_oil, aes(x = Longitude, y = Latitude, color = 'red'))
retire_count = filtered_oil %>%
group_by(., Borough) %>%
summarize(., count = n())
count_plot = ggplot(data=filtered_oil, aes(x = Borough))
borough = oil %>%
group_by(., Borough)%>%
summarize(., cnt = n())
leaflet_nyc_oil = leaflet() %>% addTiles() %>% addPolygons(data = council)
area.points = fortify(council)
b.points = fortify(counties)
b_filter = clean_oil %>%
filter(., Borough %in% 1) %>%
distinct(., Council.District)
map_part = b.points %>%
filter(., id %in% c(0:4))
map2 = ggplot() + geom_polygon(data=map_part, aes(x = long, y = lat, group = group)) + theme(plot.subtitle = element_text(vjust = 1),
plot.caption = element_text(vjust = 1),
legend.position = "none")
# set aside to put back into shiny
gas_select = reactive({
switch (input$gas,
"Con Edison" = "Con Edison",
"National Grid" = "National Grid",
"All" = c("Con Edison", "National Grid")
)
})
filtered_oil2 = reactive({
oil2 %>%
filter(., Retirement >= input$year[1] & Retirement <= input$year[2]) %>%
filter(., Natural.Gas.Utility..Con.Edison.or.National.Grid == gas_select())
})
test = read.csv('clean_oil.csv')
class(test$Borough)
test2 = filter(test, Borough %in% 1)
head(test2$Borough)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
setwd("~/NYCDSA_proj/projects/Nyc_Oil")
runApp()
runApp()
library(ggplot2)
library(dplyr)
#1
q11 = ggplot(data = cars, aes(x= dist, y = speed)) + geom_point()
#1.2
q12 = q11 + xlab('Stopping Distance (ft)') + ylab('Speed (mpg)')
q12
#1.3
q13 = ggplot(data = cars, aes(x= dist, y = speed)) + geom_point(shape = 17, color = 'red')
q13
install.packages("regexr")
library(ggplot2)
library(dplyr)
#1
q11 = ggplot(data = cars, aes(x= dist, y = speed)) + geom_point()
#1.2
q12 = q11 + xlab('Stopping Distance (ft)') + ylab('Speed (mpg)')
q12
#1.3
q13 = ggplot(data = cars, aes(x= dist, y = speed)) + geom_point(shape = 17, color = 'red')
q13
data(faithful)
#1
faithful = faithful %>%
mutate(., length = ifelse(waiting > 70.9, 'long', 'short')) #mean of waiting
head(faithful)
#2
q22 = ggplot(data = faithful, aes(x = length, y = waiting)) + geom_boxplot()
q22
#3
q23 = ggplot(data = faithful) + geom_density(aes(x=waiting, group= length))
q23
#4
#binary distribution of wait times
library(tidyr)
library(ggplot2)
library(dplyr)
load(url('https://s3.amazonaws.com/graderdata/Knicks.rda'))
wl = data %>%
group_by(., season, win) %>%
summarise(., cnt= n()) %>%
spread(., key = win, value = cnt) %>%
mutate(., ratio = W/L)
head(wl)
q31 = ggplot(data = wl, aes(x = season, y = ratio)) + geom_bar(stat = 'identity')
q31
#2
wlh = data %>%
group_by(., season, win, visiting) %>%
filter(., visiting == 1)%>%
summarise(., cnt= n()) %>%
spread(., key = win, value = cnt)
wla = data %>%
group_by(., season, win, visiting) %>%
filter(., visiting == 0)%>%
summarise(., cnt= n()) %>%
spread(., key = win, value = cnt)
wl2 = rbind(wla, wlh) %>%
mutate(., ratio = W/L)
q32 = ggplot(data = wl2, aes(x = season, y= ratio)) + geom_bar(stat = 'identity', aes(fill =  visiting), position = 'dodge')
print(q32)
print(wl2)
#3
point_hist = function(x) {
cut = data %>%
filter(., season == levels(data$season)[x])
print(
ggplot(data = cut, aes(x=points)) +
geom_histogram() +
labs(xlab = str(levels(data$season)[x]))
)
}
sapply(1:5, point_hist)
# Question 1
library(ggplot2)
data(cars)
plot(cars$speed,cars$dist)
ggplot(data = cars , aes(x = speed, y=dist))+
geom_point(col="red",pch = 17)+
xlab("Speed (mpg)")+
ylab("Stopping Distance (ft)")+
ggtitle("Relationship between Speed and Stopping Distance ")
library(ggplot2)
library(dplyr)
#1
q11 = ggplot(data = cars, aes(x= dist, y = speed)) + geom_point()
#1.2
q12 = q11 + xlab('Stopping Distance (ft)') + ylab('Speed (mpg)')
q12
#1.3
q13 = ggplot(data = cars, aes(x= dist, y = speed)) + geom_point(pch = 17, color = 'red')
q13
# Question 3
library(dplyr)
load(url('https://s3.amazonaws.com/graderdata/Knicks.rda'))
knicks <- tbl_df(data)
# 3.1
knicks1 <- group_by(knicks, season) %>%
summarise(ratio=sum(win=="W")/n())
ggplot(knicks1, aes(x=season, y=ratio)) + geom_bar(stat="identity")
# 3.2
knicks2 <- group_by(knicks, season, visiting) %>%
summarise(ratio=sum(win=="W")/n())
ggplot(knicks2, aes(x=season,y=ratio)) +
geom_bar(aes(fill=visiting), stat='identity',position='dodge')
# 3.3
ggplot(knicks,aes(x=points)) +
geom_histogram()+
facet_wrap(~season)
#### Difference between facet_wrap and facet_grid
#### https://www3.nd.edu/~steve/computing_with_data/13_Facets/facets.html
# 3.4
knicks3 <- group_by(knicks, opponent) %>%
summarise(ratio=sum(win=="W")/n(), diff=mean(points-opp))
ggplot(knicks3,aes(x=diff, y=ratio)) +
geom_point(color='red4',size=4)+
geom_hline(yintercept=0.5,colour='grey20',size=0.5,linetype=2)+
geom_vline(xintercept=0,colour='grey20',size=0.5,linetype=2)+
geom_text(aes(x=diff,y=ratio,label=opponent),
hjust=0.7, vjust=1.4,angle = -30)+
theme_bw()
# The plot shows that the more favorable the point differece, the higher the  win ratio, which sounds reasonable
library(stringr)
library(regexr)
library(ggplot2)
names = read.table('yob2014.txt', sep = ",", col.names = c('name','sex', 'cnt'))
install.packages("stringr")
install.packages("stringr")
?duplicated
# Question 4
# 4.1
library(dplyr)
yob2014<- read.csv("names/yob2014.txt",
header = FALSE,
col.names = c("name","sex","number"),
stringsAsFactors = FALSE)
?list.files
?do.call
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
head(filred_oil2)
head(filtered_oil2)
head(clean_oil)
head(test)
pie = gvisPieChart(test$Building.Type)
head(test$Building.Type)
class(test$Building.Type)
piegroup = test%>%
group_by(., Building.Type) %>%
summarise(., N_BType = n())
head(piegroup)
pie = gvisPieChart(piegroup)
pie
plot(pie)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?fluidRow
runApp()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
?geom_polygon
?plotOutput
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?box
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
